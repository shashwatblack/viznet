{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load main.py\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(args, model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "def main():\n",
    "    # Training settings\n",
    "    parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "    parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                        help='input batch size for training (default: 64)')\n",
    "    parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                        help='input batch size for testing (default: 1000)')\n",
    "    parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                        help='number of epochs to train (default: 10)')\n",
    "    parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n",
    "                        help='learning rate (default: 0.01)')\n",
    "    parser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n",
    "                        help='SGD momentum (default: 0.5)')\n",
    "    parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                        help='disables CUDA training')\n",
    "    parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                        help='random seed (default: 1)')\n",
    "    parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                        help='how many batches to wait before logging training status')\n",
    "    \n",
    "    parser.add_argument('--save-model', action='store_true', default=False,\n",
    "                        help='For Saving the current Model')\n",
    "    args = parser.parse_args()\n",
    "    use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=args.test_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "\n",
    "    model = Net().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "        test(args, model, device, test_loader)\n",
    "\n",
    "    if (args.save_model):\n",
    "        torch.save(model.state_dict(),\"mnist_cnn.pt\")\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        conv1=x\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        pool1=x\n",
    "        x = F.relu(self.conv2(x))\n",
    "        conv2=x\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        pool2=x\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        fc1 = x\n",
    "        x = self.fc2(x)\n",
    "        fc2 = x\n",
    "        return [conv1,pool1,conv2,pool2,fc1,fc2,F.log_softmax(x, dim=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=64) #args.test_batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=800, out_features=500, bias=True)\n",
       "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "model = Net()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "model.load_state_dict(torch.load('mnist_cnn.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'' was not found in history, as a file, url, nor in the user namespace.\n",
      "tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5,\n",
      "        4, 0, 7, 4, 0, 1, 3, 1, 3, 4, 7, 2, 7, 1, 2, 1, 1, 7, 4, 2, 3, 5, 1, 2,\n",
      "        4, 4, 6, 3, 5, 5, 6, 0, 4, 1, 9, 5, 7, 8, 9, 3])\n",
      "torch.Size([64, 1, 28, 28])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-3e9bae60173c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mconv1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpool1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpool2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfc2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconv2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfc1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfc2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 7)"
     ]
    }
   ],
   "source": [
    "%save get_image.py\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        conv1=x\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        pool1=x\n",
    "        x = F.relu(self.conv2(x))\n",
    "        conv2=x\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        pool2=x\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        fc1 = x\n",
    "        x = self.fc2(x)\n",
    "        fc2 = x\n",
    "        return [conv1,pool1,conv2,pool2,fc1,fc2,F.log_softmax(x, dim=1)]\n",
    "\n",
    "device = 'cuda'\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "model = Net()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "model.load_state_dict(torch.load('mnist_cnn.pt'))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "seen_num = set()\n",
    "root = os.path.join('mnist images')\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        print(target)\n",
    "        print(data.shape)\n",
    "        output = model(data)\n",
    "        conv1,pool1,conv2,pool2,fc1,fc2,_ = output\n",
    "        print(conv1[0].shape, conv2[0].shape, fc1[0].shape, fc2[0].shape)\n",
    "        target = list(target.numpy())\n",
    "        for idx,label in enumerate(target):\n",
    "            if label not in seen_num:\n",
    "                seen_num.add(label)\n",
    "                image_path=os.path.join(root,str(label))\n",
    "                print(image_path)\n",
    "                #===============================================================\n",
    "                input_image = data[i][0]\n",
    "                input_image = np.array(np.uint8(input_image),dtype=float)\n",
    "                input_image = Image.fromarray(input_image)\n",
    "                input_imgray = input_image.convert('L')\n",
    "                input_image = np.array(list(input_imgray.getdata()), float)\n",
    "                input_image.shape = (input_imgray.size[1], input_imgray.size[0])\n",
    "                input_image = (input_image/2)*255\n",
    "                input_image = np.round(input_image)\n",
    "                numpy.save(os.path.join(image_path,'input','input.npy'), input_image)\n",
    "                input_image = Image.fromarray(input_image)\n",
    "                input_image = pil.convert('RGB')\n",
    "                input_image.save(os.path.join(image_path,'input','input.png'))\n",
    "                #================================================================\n",
    "                image_conv1 = conv1[i]\n",
    "                i=0\n",
    "                image = None\n",
    "                input_image=None\n",
    "                for i,image in enumerate(image_conv1):\n",
    "                    input_image = np.array(np.uint8(image),dtype=float)\n",
    "                    input_image = Image.fromarray(input_image)\n",
    "                    input_imgray = input_image.convert('L')\n",
    "                    input_image = np.array(list(input_imgray.getdata()), float)\n",
    "                    input_image.shape = (input_imgray.size[1], input_imgray.size[0])\n",
    "                    #print(input_image[np.argmax(input_image,axis=1)])\n",
    "                    #max_val = input_image(np.argmax(input_image))\n",
    "                    max_value =np.amax(input_image)\n",
    "#                     if max_value == 0:\n",
    "#                         print(input_image)\n",
    "#                         assert(max_value!=0)\n",
    "                    #print(a)\n",
    "                    input_image = (input_image/max_value)*255\n",
    "                    input_image = np.round(input_image)\n",
    "                    numpy.save(os.path.join(image_path,'conv1','pickles','feature_map{}.npy'.format(i)),input_image)\n",
    "                    #print(input_image)\n",
    "                    input_image = Image.fromarray(input_image)\n",
    "                    input_image = pil.convert('RGB')\n",
    "                    input_image.save(os.path.join(image_path,'conv1','imgs','feature_map{}.png'.format(i)))\n",
    "                #================================================================\n",
    "                image_pool1 = pool1[i]\n",
    "                i=0\n",
    "                image = None\n",
    "                input_image=None\n",
    "                for i,image in enumerate(image_pool1):\n",
    "                    input_image = np.array(np.uint8(image),dtype=float)\n",
    "                    input_image = Image.fromarray(input_image)\n",
    "                    input_imgray = input_image.convert('L')\n",
    "                    input_image = np.array(list(input_imgray.getdata()), float)\n",
    "                    input_image.shape = (input_imgray.size[1], input_imgray.size[0])\n",
    "                    max_value =np.amax(input_image)\n",
    "                    input_image = (input_image/max_value)*255\n",
    "                    input_image = np.round(input_image)\n",
    "                    numpy.save(os.path.join(image_path,'pool1','pickles','feature_map{}.npy'.format(i)),input_image)\n",
    "                    input_image = Image.fromarray(input_image)\n",
    "                    input_image = pil.convert('RGB')\n",
    "                    input_image.save(os.path.join(image_path,'pool1','imgs','feature_map{}.png'.format(i)))\n",
    "                #=================================================================\n",
    "                image_conv2 = conv2[i]\n",
    "                i=0\n",
    "                image = None\n",
    "                input_image=None\n",
    "                for i,image in enumerate(image_conv2):\n",
    "                    input_image = np.array(np.uint8(image),dtype=float)\n",
    "                    input_image = Image.fromarray(input_image)\n",
    "                    input_imgray = input_image.convert('L')\n",
    "                    input_image = np.array(list(input_imgray.getdata()), float)\n",
    "                    input_image.shape = (input_imgray.size[1], input_imgray.size[0])\n",
    "                    max_value =np.amax(input_image)\n",
    "                    input_image = (input_image/max_value)*255\n",
    "                    input_image = np.round(input_image)\n",
    "                    numpy.save(os.path.join(image_path,'conv2','pickles','feature_map{}.npy'.format(i)),input_image)\n",
    "                    input_image = Image.fromarray(input_image)\n",
    "                    input_image = pil.convert('RGB')\n",
    "                    input_image.save(os.path.join(image_path,'conv2','imgs','feature_map{}.png'.format(i)))\n",
    "                #=================================================================\n",
    "                image_pool2 = pool2[i]\n",
    "                i=0\n",
    "                image = None\n",
    "                input_image=None\n",
    "                for i,image in enumerate(image_conv2):\n",
    "                    input_image = np.array(np.uint8(image),dtype=float)\n",
    "                    input_image = Image.fromarray(input_image)\n",
    "                    input_imgray = input_image.convert('L')\n",
    "                    input_image = np.array(list(input_imgray.getdata()), float)\n",
    "                    input_image.shape = (input_imgray.size[1], input_imgray.size[0])\n",
    "                    max_value =np.amax(input_image)\n",
    "                    input_image = (input_image/max_value)*255\n",
    "                    input_image = np.round(input_image)\n",
    "                    numpy.save(os.path.join(image_path,'pool2','pickles','feature_map{}.npy'.format(i)),input_image)\n",
    "                    input_image = Image.fromarray(input_image)\n",
    "                    input_image = pil.convert('RGB')\n",
    "                    input_image.save(os.path.join(image_path,'pool2','imgs','feature_map{}.png'.format(i)))\n",
    "                #==================================================================\n",
    "                image = None\n",
    "                input_image=None\n",
    "                image=fc1[i]\n",
    "                \n",
    "                input_image = np.array(np.uint8(image),dtype=float)\n",
    "                input_image = Image.fromarray(np.array([input_image]))\n",
    "                input_imgray = input_image.convert('L')\n",
    "                input_image = np.array(list(input_imgray.getdata()), float)\n",
    "                input_image.shape = (input_imgray.size[1], input_imgray.size[0])\n",
    "                max_value =np.amax(input_image)\n",
    "                input_image = (input_image/max_value)*255\n",
    "                input_image = np.round(input_image)\n",
    "                numpy.save(os.path.join(image_path,'fc1','pickles','feature_map{}.npy'.format(i)),input_image)\n",
    "                input_image = Image.fromarray(input_image)\n",
    "                input_image = pil.convert('RGB')\n",
    "                input_image.save(os.path.join(image_path,'fc1','imgs','feature_map{}.png'.format(i)))\n",
    "                #====================================================================\n",
    "                image = None\n",
    "                input_image=None\n",
    "                image=fc2[i]\n",
    "                input_image = np.array(np.uint8(image),dtype=float)\n",
    "                input_image = Image.fromarray(np.array([input_image]))\n",
    "                input_imgray = input_image.convert('L')\n",
    "                input_image = np.array(list(input_imgray.getdata()), float)\n",
    "                input_image.shape = (input_imgray.size[1], input_imgray.size[0])\n",
    "                max_value =np.amax(input_image)\n",
    "                input_image = (input_image/max_value)*255\n",
    "                input_image = np.round(input_image)\n",
    "                numpy.save(os.path.join(image_path,'fc1','pickles','feature_map{}.npy'.format(i)),input_image)\n",
    "                input_image = Image.fromarray(input_image)\n",
    "                input_image = pil.convert('RGB')\n",
    "                input_image.save(os.path.join(image_path,'fc1','imgs','feature_map{}.png'.format(i)))\n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object does not support indexing",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-c6732a414d4d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'DataLoader' object does not support indexing"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0307, Accuracy: 9896/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "        pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:emo]",
   "language": "python",
   "name": "conda-env-emo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
